{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "# rmac \n",
    "def rmac(x, L=3, eps=1e-6):\n",
    "    ovr = 0.4 # desired overlap of neighboring regions\n",
    "    steps = torch.Tensor([2, 3, 4, 5, 6, 7]) # possible regions for the long dimension\n",
    "\n",
    "    W = x.size(3)\n",
    "    H = x.size(2)\n",
    "\n",
    "    w = min(W, H)\n",
    "    w2 = math.floor(w/2.0 - 1) # 向下去整\n",
    "\n",
    "    b = (max(H, W)-w)/(steps-1)\n",
    "    (tmp, idx) = torch.min(torch.abs(((w**2 - w*b)/w**2)-ovr), 0) # steps(idx) regions for long dimension\n",
    "\n",
    "    # region overplus per dimension\n",
    "    Wd = 0;\n",
    "    Hd = 0;\n",
    "    if H < W:  \n",
    "        Wd = idx.item() + 1\n",
    "    elif H > W:\n",
    "        Hd = idx.item() + 1\n",
    "\n",
    "    v = F.max_pool2d(x, (x.size(-2), x.size(-1)))\n",
    "    v = v / (torch.norm(v, p=2, dim=1, keepdim=True) + eps).expand_as(v)\n",
    "\n",
    "    for l in range(1, L+1):\n",
    "        wl = math.floor(2*w/(l+1))\n",
    "        wl2 = math.floor(wl/2 - 1)\n",
    "\n",
    "        if l+Wd == 1:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = (W-wl)/(l+Wd-1)\n",
    "        cenW = torch.floor(wl2 + torch.Tensor(range(l-1+Wd+1))*b) - wl2 # center coordinates\n",
    "        if l+Hd == 1:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = (H-wl)/(l+Hd-1)\n",
    "        cenH = torch.floor(wl2 + torch.Tensor(range(l-1+Hd+1))*b) - wl2 # center coordinates\n",
    "            \n",
    "        for i_ in cenH.tolist():\n",
    "            for j_ in cenW.tolist():\n",
    "                if wl == 0:\n",
    "                    continue\n",
    "                R = x[:,:,(int(i_)+torch.Tensor(range(wl)).long()).tolist(),:]\n",
    "                R = R[:,:,:,(int(j_)+torch.Tensor(range(wl)).long()).tolist()]\n",
    "                vt = F.max_pool2d(R, (R.size(-2), R.size(-1)))\n",
    "                vt = vt / (torch.norm(vt, p=2, dim=1, keepdim=True) + eps).expand_as(vt)\n",
    "                v += vt\n",
    "\n",
    "    return v\n",
    "# RMAC 类\n",
    "class RMAC(nn.Module):\n",
    "\n",
    "    def __init__(self, L=3, eps=1e-6):\n",
    "        super(RMAC,self).__init__()\n",
    "        self.L = L\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return rmac(x, L=self.L, eps=self.eps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'L=' + '{}'.format(self.L) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,1,7,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr = 0.4 # desired overlap of neighboring regions\n",
    "steps = torch.Tensor([2, 3, 4, 5, 6, 7]) # possible regions for the long dimension\n",
    "\n",
    "W = x.size(3)\n",
    "H = x.size(2)\n",
    "\n",
    "w = min(W, H)\n",
    "w2 = math.floor(w/2.0 - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (max(H, W)-w)/(steps-1)\n",
    "(tmp, idx) = torch.min(torch.abs(((w**2 - w*b)/w**2)-ovr), 0) # steps(idx) regions for long dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6000), tensor(5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(1,1,7,7)\n",
    "Y = torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3629, -2.0585,  0.1187,  1.7724,  0.4331, -0.4824,  1.0489],\n",
       "           [ 0.4368,  2.2646,  0.1899, -1.0467, -0.4229,  0.1327,  0.6670],\n",
       "           [-0.6352,  0.1034, -0.3733, -1.2272,  0.0541,  0.8764,  0.3084],\n",
       "           [-0.1784, -0.3495, -1.3299, -1.8515,  0.1720, -1.4369,  0.1595],\n",
       "           [ 1.7392, -0.9837, -0.6336,  0.4657,  0.2015, -1.9127,  0.2246],\n",
       "           [-0.0239, -1.5665,  1.5271, -0.2848, -0.0039,  0.3882,  0.4971],\n",
       "           [-1.5186, -1.4538,  2.0065, -0.9816, -0.2502, -0.4006,  1.2704]]]]),\n",
       " tensor([-2.0163]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.expand_as(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163],\n",
       "          [-2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163],\n",
       "          [-2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163],\n",
       "          [-2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163],\n",
       "          [-2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163],\n",
       "          [-2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163],\n",
       "          [-2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163, -2.0163]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
